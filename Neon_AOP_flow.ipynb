{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2389b62-0b84-4c4b-ad24-087e9c3d53b4",
   "metadata": {},
   "source": [
    "## Setup Flow with Prefect Cloud\n",
    "\n",
    "**Only need to do this one time**\n",
    "\n",
    "Set backend to cloud (unless running prefect server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5bd4e5-802b-43fb-8e36-8f5a0c5c83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mBackend switched to cloud\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!prefect backend cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df3aa1-71df-43d3-8024-60e687f1095d",
   "metadata": {},
   "source": [
    "Authentification - https://docs.prefect.io/orchestration/tutorial/overview.html#create-an-api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41225647-f20c-40c5-8dfe-48c8a4707c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Prefect Cloud API key: ······················\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "prompts = 'Enter your Prefect Cloud API key: '\n",
    "apikey = getpass(prompt='Enter your Prefect Cloud API key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc66b14-9d30-4571-b6ec-70a88091286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch ~/.prefect/config.toml\n",
    "!echo -en \"[cloud]\\nauth_token = \\\"$apikey\\\"\" >> ~/.prefect/config.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f50847-b3fe-4e4f-82e5-42764ad8f8b9",
   "metadata": {},
   "source": [
    "Create a project on Prefect Cloud - https://docs.prefect.io/orchestration/tutorial/first.html#creating-a-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00609d-715d-4155-970c-4583e2e5e5e2",
   "metadata": {},
   "source": [
    "## Create Dask Execution Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8a91f1-c015-4876-b2d2-f5d6a0f410e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask, dask.distributed\n",
    "dask.config.set({'distributed.dashboard.link': '/proxy/{port}/status'})\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf08306-c48e-4904-8a81-b314526d323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_type = 'local'\n",
    "#cluster_type = 'HPC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b949081f-bff4-4126-b212-07d4edb0f45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41697</li>\n",
       "  <li><b>Dashboard: </b><a href='/proxy/8787/status' target='_blank'>/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>24.87 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41697' processes=6 threads=12, memory=24.87 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cluster_type == 'local':\n",
    "    dask.config.set({'distributed.dashboard.link': '/proxy/{port}/status'})\n",
    "    cluster = LocalCluster(n_workers=6)#,threads_per_worker=2)\n",
    "    cl = Client(cluster)\n",
    "elif cluster_type == 'HPC':\n",
    "    import dask_jobqueue as jq\n",
    "    dask.config.set({'distributed.dashboard.link': '/user/{user}/proxy/{port}/status'})\n",
    "    partition='brief-low'#,debug,mem,mem-low'\n",
    "    num_processes = 10\n",
    "    num_threads_per_processes = 4\n",
    "    mem = 3.2*num_processes*num_threads_per_processes#*1.25\n",
    "    n_cores_per_job = num_processes*num_threads_per_processes\n",
    "    container = 'docker://rowangaffney/data_science_im_rs:latest'\n",
    "    env = 'py_geo'\n",
    "    clust = jq.SLURMCluster(queue=partition,\n",
    "                            processes=num_processes,\n",
    "                            cores=n_cores_per_job,\n",
    "                            memory=str(mem)+'GB',\n",
    "                            interface='ib0',\n",
    "                            local_directory='$TMPDIR',\n",
    "                            death_timeout=30,\n",
    "                            python=\"singularity -vv exec {} /opt/conda/envs/{}/bin/python\".format(container,env),\n",
    "                            walltime='02:00:00',\n",
    "                            job_extra=[\"--output=/dev/null\",\"--error=/dev/null\"])\n",
    "    cl=Client(clust)\n",
    "    dash_addr = '''/user/{}/proxy/{}/status'''.format(os.environ['USER'],cl.scheduler_info()['services']['dashboard'])\n",
    "    print('Dask Lab Extention Address (paste into the search box): '+dash_addr)\n",
    "    \n",
    "    #Scale Cluster \n",
    "    num_jobs=8\n",
    "    clust.scale(n=num_jobs*num_processes)\n",
    "else:\n",
    "    print('Cluster type not defined')\n",
    "ncpus = int(np.unique(np.array(list(cl.nthreads().values())))[0])\n",
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158e83c-c005-49a9-b802-01f2ec1bbb01",
   "metadata": {},
   "source": [
    "## Build Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403b6fc0-99f5-4e29-ba89-17c4fabb3c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_geo/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-egqcgidy because the default path (/home/jovyan/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "#Import Prefect Packages\n",
    "from prefect import task, Flow, unmapped, Parameter\n",
    "from prefect.executors import DaskExecutor\n",
    "import prefect\n",
    "\n",
    "#Import custom tasks\n",
    "from prefect_tasks import tasks as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8072f3-3e70-4866-845c-5b8a5fa2d12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81fdb9a-4866-4779-bc32-de600a4d9757",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(name = 'Mosaic_NEON_AOP_Hyper',\n",
    "          executor=DaskExecutor(address=cl.scheduler_info()['address'])\n",
    "         ) as flow:\n",
    "    \n",
    "    #### Define Parameters ###\n",
    "    site_p = Parameter('site_p', default = 'CPER')\n",
    "    processDate_p = Parameter('processDate_p', default = '2017-05')\n",
    "    \n",
    "    \n",
    "    #Task1: Get metadata about the data product for a specific site / date\n",
    "    site_dict = t.query_data_urls(site=site_p,\n",
    "                                processDate=processDate_p)\n",
    "    \n",
    "    #Task2: Get the URLS for all the h5 files.\n",
    "    h5_files = t.query_file_urls(site_dict=site_dict,\n",
    "                               site=site_p,\n",
    "                               processDate=processDate_p)\n",
    "    \n",
    "    #Task3: Setup the BRDF and TOPO correction configurations\n",
    "    workflow_meta = t.BRDF_TOPO_Config.map(pipeline_dict = h5_files,\n",
    "                                        site=unmapped(site_p),\n",
    "                                        processDate=unmapped(processDate_p),\n",
    "                                        cpus=unmapped(ncpus))\n",
    "    \n",
    "    #Task4: Download the files to folder ./{site}_{procossDate}/\n",
    "    download_res = t.download_file.map(pipeline_dict = workflow_meta,\n",
    "                                 site=unmapped(site_p),\n",
    "                                 processDate=unmapped(processDate_p))\n",
    "    \n",
    "    #Task5: Get the metadata for each file\n",
    "    workflow_meta = t.get_file_meta.map(pipeline_dict=download_res)\n",
    "    \n",
    "    #Task6: Write the metadata for each file to a human readable file (.json)\n",
    "    metadata_exported = t.write_pipeline_meta(pipeline_dict = workflow_meta,\n",
    "                                            site=unmapped(site_p),\n",
    "                                            processDate=unmapped(processDate_p))\n",
    "    \n",
    "    #Task7: Apply the BRDF and TOPO corrections to the data\n",
    "    ht_pipeline = t.apply_corrections_mosaic.map(pipeline_dict=workflow_meta,\n",
    "                                               site=unmapped(site_p),\n",
    "                                               processDate=unmapped(processDate_p))\n",
    "    \n",
    "    #Task8: Get the mask for each flight line for mosaicing the flights together\n",
    "    ht_pipeline2 = t.pixel_mosaic_mask.map(pipeline_dict = ht_pipeline,\n",
    "                                        pipeline_list=unmapped(ht_pipeline))\n",
    "    \n",
    "    #Task9: Get the extents of all the flights for the final mosaic.\n",
    "    extent = t.moasic_extent(ht_pipeline2)\n",
    "    \n",
    "    #Task10: Mosaic the BRDF and Topo corrected flights using pixels to the lowest sensor to-zenith angle\n",
    "    success = t.mosaic(pipeline_list=ht_pipeline,\n",
    "                     extents=extent,\n",
    "                     site=site_p,\n",
    "                     processDate=processDate_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c970e-d8bc-4075-b6f0-31e833cd0518",
   "metadata": {},
   "source": [
    "## Register FLow and Start of Local Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5567d8b-cb64-483f-bc3d-a42b795cba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow URL: https://cloud.prefect.io/rowan-data-workflows/flow/a7562972-e524-435d-8076-edb5643e5f07\n",
      " └── ID: b585ff3c-3ace-4080-9664-2738b028294e\n",
      " └── Project: Neon_AOP_BRDF_Mosaic\n",
      " └── Labels: ['a57d20bac99f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'b585ff3c-3ace-4080-9664-2738b028294e'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the flow under the \"tutorial\" project\n",
    "flow.register(project_name=\"Neon_AOP_BRDF_Mosaic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eabca2-e23e-45e1-84a0-5731ca1d99b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-07-01 03:58:53,608] INFO - agent | Registering agent...\n",
      "[2021-07-01 03:58:53,830] INFO - agent | Registration successful!\n",
      "\n",
      " ____            __           _        _                    _\n",
      "|  _ \\ _ __ ___ / _| ___  ___| |_     / \\   __ _  ___ _ __ | |_\n",
      "| |_) | '__/ _ \\ |_ / _ \\/ __| __|   / _ \\ / _` |/ _ \\ '_ \\| __|\n",
      "|  __/| | |  __/  _|  __/ (__| |_   / ___ \\ (_| |  __/ | | | |_\n",
      "|_|   |_|  \\___|_|  \\___|\\___|\\__| /_/   \\_\\__, |\\___|_| |_|\\__|\n",
      "                                           |___/\n",
      "\n",
      "[2021-07-01 03:58:54,003] INFO - agent | Starting LocalAgent with labels ['a57d20bac99f']\n",
      "[2021-07-01 03:58:54,003] INFO - agent | Agent documentation can be found at https://docs.prefect.io/orchestration/\n",
      "[2021-07-01 03:58:54,003] INFO - agent | Waiting for flow runs...\n"
     ]
    }
   ],
   "source": [
    "!prefect agent local start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bdace-5f60-42de-846c-bc9a46fba524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py_geo]",
   "language": "python",
   "name": "conda-env-py_geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
